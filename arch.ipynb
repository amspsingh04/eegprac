{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb66690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '3'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.Graph()\n",
    "\n",
    "# The Location of train_data，train_labels，test_data，test_labels\n",
    "# DataSet Address\n",
    "DIR = 'E:/eeg-prac/Dataset/Excels/'\n",
    "\n",
    "# Model Saver Address\n",
    "SAVE = 'E:/eeg-prac/Models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0630c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(DIR + 'Training_labels.csv', header=None)\n",
    "train_data = np.array(train_data).astype('float32')\n",
    "\n",
    "train_labels = pd.read_csv(DIR + 'Training_labels.csv', header=None)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "test_data = pd.read_csv(DIR + 'Test_data.csv', header=None)\n",
    "test_data = np.array(test_data).astype('float32')\n",
    "\n",
    "test_labels = pd.read_csv(DIR + 'Test_labels.csv', header=None)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d6b5423",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_batch = train_data.shape[0] // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eded1e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.random.truncated_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.01, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def variable_summaries(name, var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean/'+ name, mean)\n",
    "\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "            tf.summary.scalar('stddev/'+name, stddev)\n",
    "\n",
    "        tf.summary.scalar('max/'+name, tf.reduce_max(var))\n",
    "        tf.summary.scalar('min/'+name, tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram/'+name, var)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a7687d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_shape = (640,)\n",
    "inputs = tf.keras.Input(shape=input_shape, name='Input_Data')\n",
    "x_reshape = layers.Reshape((32, 20, 1), name='Reshape_Data')(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b40e9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, initializers, regularizers\n",
    "model = models.Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da819153",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Conv2D(\n",
    "    filters=32, \n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='SAME',\n",
    "    use_bias=True,\n",
    "    kernel_initializer=initializers.TruncatedNormal(stddev=0.01),\n",
    "    bias_initializer=initializers.Constant(value=0.01),\n",
    "    name='Convolutional_1'\n",
    "))\n",
    "model.add(layers.LeakyReLU(name='h_conv1_Acti'))\n",
    "model.add(layers.Dropout(\n",
    "    rate=0.5,  \n",
    "    name='h_conv1_drop'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0d7c5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Conv2D(\n",
    "    filters=32, \n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='SAME',\n",
    "    use_bias=True,\n",
    "    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "    bias_initializer=tf.keras.initializers.Constant(value=0.01),\n",
    "    name='Convolutional_2'\n",
    "))\n",
    "model.add(layers.BatchNormalization(name='h_conv2_BN'))\n",
    "model.add(layers.Dropout(rate=0.5, name='h_conv2_drop'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9448407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='SAME',\n",
    "    use_bias=True,\n",
    "    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "    bias_initializer=tf.keras.initializers.Constant(value=0.01),\n",
    "    name='Convolutional_3'\n",
    "))\n",
    "model.add(layers.LeakyReLU(name='h_conv3_Acti'))\n",
    "model.add(layers.Dropout(rate=0.5, name='h_conv3_drop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0869a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.MaxPooling2D(\n",
    "    pool_size=(2, 2),\n",
    "    strides=(2, 2),\n",
    "    padding='SAME',\n",
    "    name='Pooling_1'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbdf53e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='VALID',  \n",
    "    use_bias=True,\n",
    "    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "    bias_initializer=tf.keras.initializers.Constant(value=0.01),\n",
    "    name='Convolutional_4'\n",
    "))\n",
    "model.add(layers.BatchNormalization(name='h_conv4_BN'))\n",
    "model.add(layers.LeakyReLU(name='h_conv4_Acti'))\n",
    "model.add(layers.Dropout(rate=0.5, name='h_conv4_drop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca7379fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='SAME',\n",
    "    use_bias=True,\n",
    "    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "    bias_initializer=tf.keras.initializers.Constant(value=0.01),\n",
    "    name='Convolutional_5'\n",
    "))\n",
    "model.add(layers.BatchNormalization(name='h_conv5_BN'))\n",
    "model.add(layers.LeakyReLU(name='h_conv5_Acti'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1559d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Conv2D(\n",
    "    filters=128,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='SAME',\n",
    "    use_bias=True,\n",
    "    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "    bias_initializer=tf.keras.initializers.Constant(value=0.01),\n",
    "    name='Convolutional_6'\n",
    "))\n",
    "model.add(layers.BatchNormalization(name='h_conv6_BN'))\n",
    "model.add(layers.LeakyReLU(name='h_conv6_Acti'))\n",
    "model.add(layers.Dropout(rate=0.5, name='h_conv6_drop'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddf9e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.MaxPooling2D(\n",
    "    pool_size=(2, 2),\n",
    "    strides=(2, 2),\n",
    "    padding='SAME',\n",
    "    name='Pooling_2'\n",
    "))\n",
    "\n",
    "model.add(layers.Flatten(name='Flatten'))\n",
    "model.add(layers.Dense(\n",
    "    512,\n",
    "    use_bias=True,\n",
    "    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "    bias_initializer=tf.keras.initializers.Constant(value=0.01),\n",
    "    name='Fully_Connected_1'\n",
    "))\n",
    "model.add(layers.BatchNormalization(name='h_fc1_BN'))\n",
    "model.add(layers.LeakyReLU(name='h_fc1_Acti'))\n",
    "model.add(layers.Dropout(rate=0.5, name='h_fc1_drop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d4f12b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(\n",
    "    4,\n",
    "    use_bias=True,\n",
    "    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "    bias_initializer=tf.keras.initializers.Constant(value=0.01),\n",
    "    activation='softmax',  # Softmax activation function is used for the output layer\n",
    "    name='OP_Layer'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02e331d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss=euclidean_distance_loss,\n",
    "              metrics=['mean_squared_error']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6faf38b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\spsin\\AppData\\Local\\Temp\\ipykernel_22612\\295768917.py\", line 12, in update_state  *\n        y_true_class = tf.equal(tf.argmax(y_true, 1), self.class_id)\n\n    ValueError: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m t3_accuracy \u001b[38;5;241m=\u001b[39m SpecificClassAccuracy(class_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     28\u001b[0m t4_accuracy \u001b[38;5;241m=\u001b[39m SpecificClassAccuracy(class_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m t1_accuracy\u001b[38;5;241m.\u001b[39mupdate_state(y_true, y_pred)\n\u001b[0;32m     31\u001b[0m t2_accuracy\u001b[38;5;241m.\u001b[39mupdate_state(y_true, y_pred)\n\u001b[0;32m     32\u001b[0m t3_accuracy\u001b[38;5;241m.\u001b[39mupdate_state(y_true, y_pred)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\metrics_utils.py:77\u001b[0m, in \u001b[0;36mupdate_state_wrapper.<locals>.decorated\u001b[1;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     70\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to run metric.update_state in replica context when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe metric was not created in TPUStrategy scope. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure the keras Metric is created in TPUstrategy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     73\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscope. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m         )\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf_utils\u001b[38;5;241m.\u001b[39mgraph_context_for_symbolic_tensors(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 77\u001b[0m     result \u001b[38;5;241m=\u001b[39m update_state_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m     79\u001b[0m     result \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mget_default_graph()\u001b[38;5;241m.\u001b[39mget_operations()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\base_metric.py:140\u001b[0m, in \u001b[0;36mMetric.__new__.<locals>.update_state_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m control_status \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\n\u001b[0;32m    137\u001b[0m ag_update_state \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m    138\u001b[0m     obj_update_state, control_status\n\u001b[0;32m    139\u001b[0m )\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ag_update_state(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    694\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filejh97nlyf.py:8\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__update_state\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtf__update_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mFunctionScope(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdate_state\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfscope\u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mSTD) \u001b[38;5;28;01mas\u001b[39;00m fscope:\n\u001b[1;32m----> 8\u001b[0m         y_true_class \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mequal, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39margmax, (ag__\u001b[38;5;241m.\u001b[39mld(y_true), \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mclass_id), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m      9\u001b[0m         y_pred_class \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mequal, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39margmax, (ag__\u001b[38;5;241m.\u001b[39mld(y_pred), \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mclass_id), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     10\u001b[0m         correct \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mlogical_and, (ag__\u001b[38;5;241m.\u001b[39mld(y_true_class), ag__\u001b[38;5;241m.\u001b[39mld(y_pred_class)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdtype), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mEagerTensor(value, ctx\u001b[38;5;241m.\u001b[39mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\spsin\\AppData\\Local\\Temp\\ipykernel_22612\\295768917.py\", line 12, in update_state  *\n        y_true_class = tf.equal(tf.argmax(y_true, 1), self.class_id)\n\n    ValueError: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.\n"
     ]
    }
   ],
   "source": [
    "y_true = None  \n",
    "y_pred = model.predict(test_data)  \n",
    "\n",
    "class SpecificClassAccuracy(tf.keras.metrics.Metric):\n",
    "    def __init__(self, class_id, name='specific_class_accuracy', **kwargs):\n",
    "        super(SpecificClassAccuracy, self).__init__(name=name, **kwargs)\n",
    "        self.class_id = class_id\n",
    "        self.correct_count = self.add_weight(name='correct_count', initializer='zeros')\n",
    "        self.total_count = self.add_weight(name='total_count', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true_class = tf.equal(tf.argmax(y_true, 1), self.class_id)\n",
    "        y_pred_class = tf.equal(tf.argmax(y_pred, 1), self.class_id)\n",
    "        correct = tf.cast(tf.logical_and(y_true_class, y_pred_class), self.dtype)\n",
    "        self.correct_count.assign_add(tf.reduce_sum(correct))\n",
    "        self.total_count.assign_add(tf.reduce_sum(tf.cast(y_true_class, self.dtype)))\n",
    "\n",
    "    def result(self):\n",
    "        return self.correct_count / self.total_count\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.correct_count.assign(0.)\n",
    "        self.total_count.assign(0.)\n",
    "\n",
    "t1_accuracy = SpecificClassAccuracy(class_id=0)\n",
    "t2_accuracy = SpecificClassAccuracy(class_id=1)\n",
    "t3_accuracy = SpecificClassAccuracy(class_id=2)\n",
    "t4_accuracy = SpecificClassAccuracy(class_id=3)\n",
    "\n",
    "t1_accuracy.update_state(y_true, y_pred)\n",
    "t2_accuracy.update_state(y_true, y_pred)\n",
    "t3_accuracy.update_state(y_true, y_pred)\n",
    "t4_accuracy.update_state(y_true, y_pred)\n",
    "\n",
    "writer = tf.summary.create_file_writer('logs')\n",
    "with writer.as_default():\n",
    "    tf.summary.scalar('Task 1 Accuracy', t1_accuracy.result(), step=0)\n",
    "    tf.summary.scalar('Task 2 Accuracy', t2_accuracy.result(), step=0)\n",
    "    tf.summary.scalar('Task 3 Accuracy', t3_accuracy.result(), step=0)\n",
    "    tf.summary.scalar('Task 4 Accuracy', t4_accuracy.result(), step=0)\n",
    "    writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a125da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KappaMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='kappa_metric', **kwargs):\n",
    "        super(KappaMetric, self).__init__(name=name, **kwargs)\n",
    "        # Placeholder initialization for all the variables that will be used to compute Kappa\n",
    "        self.p0 = self.add_weight(name='p0', initializer='zeros')\n",
    "        self.pe = self.add_weight(name='pe', initializer='zeros')\n",
    "        self.Test_Set_Num = None  # Replace with appropriate value\n",
    "\n",
    "    def update_state(self, *args, **kwargs):\n",
    "        # Update methods to calculate p0 and pe, considering the variables might be like T1_T1, T1_T2, etc.\n",
    "        pass\n",
    "    \n",
    "    def result(self):\n",
    "        return (self.p0 - self.pe) / (1 - self.pe)\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.p0.assign(0)\n",
    "        self.pe.assign(0)\n",
    "\n",
    "kappa_metric = KappaMetric()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',   \n",
    "    loss='categorical_crossentropy',  \n",
    "    metrics=[kappa_metric]  \n",
    ")\n",
    "\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs', update_freq='epoch')\n",
    "\n",
    "model.fit(\n",
    "    x=train_data, \n",
    "    y=train_labels, \n",
    "    epochs=2019, \n",
    "    batch_size=batch_size,  # Define batch_size appropriately\n",
    "    verbose=1, \n",
    "    callbacks=[tb_callback], \n",
    "    validation_data=(test_data, test_labels)\n",
    ")\n",
    "\n",
    "output_prediction = model.predict(test_data)\n",
    "np.savetxt(\"prediction.csv\", output_prediction, delimiter=\",\")\n",
    "np.savetxt(\"labels.csv\", test_labels, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
